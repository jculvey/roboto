{
  "name": "robots.txt",
  "version": "1.0.0",
  "description": "robots.txt middleware for express/connect to server up your robots.txt",
  "main": "index.js",
  "publishConfig": {
    "registry": "http://registry.npmjs.org/"
  },
  "scripts": {
    "lint": "./node_modules/.bin/jshint . --reporter=./node_modules/jshint-full-path/index.js",
    "pretest": "npm run-script lint",
    "test": "./node_modules/.bin/istanbul test ./node_modules/.bin/_mocha -- -R spec",
    "prepublish": "npm prune"
  },
  "author": {
    "name": "Tom Gallacher"
  },
  "license": "New BSD",
  "devDependencies": {
    "jshint-full-path": "~0.1.0",
    "mocha": "^1.18.2",
    "istanbul": "^0.2.7"
  },
  "readme": "## Robots.txt\n\nPass in the location of your `robots.txt` file on the file system, and this module\nwill return you a piece of Connect/Express middleware that will serve it at `GET /robots.txt`.\n\nThis makes one *synchronous* call to read the file upon start up, then reads it from memory\nfor every request. If you gave the wrong path, you will know about it at startup. Cache headers\nare set for you.\n\n## Installation\n\n    npm install --save robots.txt\n\n## Usage\n\n    var robots = require('robots.txt')\n\n    // Pass in the absolute path to your robots.txt file\n    app.use(robots(__dirname + '/robots.txt'))\n\n## Credits\nBuilt by [Tom Gallacher](http://twitter.com/tomgco) and [Ben Gourley](https://github.com/bengourley)\n\n## Licence\nLicensed under the [New BSD License](http://opensource.org/licenses/bsd-license.php)\n",
  "readmeFilename": "README.md",
  "_id": "robots.txt@1.0.0",
  "dist": {
    "shasum": "4d32a65c50c2670e2f86aed49c7fa2a40257096a"
  },
  "_from": "robots.txt@",
  "_resolved": "https://registry.npmjs.org/robots.txt/-/robots.txt-1.0.0.tgz"
}
